{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Implementation of Handwritting recognition with MNIST dataset using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import input_data # For processing MNIST images \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding command line flags for parameters and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging summaries to: softmax_logs\n"
     ]
    }
   ],
   "source": [
    "tf.app.flags.DEFINE_string(\"log_dir\",\"softmax_logs\",\"Directory for saving the summaries\")\n",
    "tf.app.flags.DEFINE_integer(\"max_it\",1000,\"Number of iterations to run\")\n",
    "tf.app.flags.DEFINE_integer(\"batch\",100,\"Batch size\")\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "print \"Logging summaries to:\",FLAGS.log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MNIST dataset from ./data directory as one hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "Training images size : (55000, 784)\n",
      "Training labels size : (55000, 10)\n",
      "Testing images size : (10000, 784)\n",
      "Testing labels size : (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "\n",
    "print \"Training images size :\",mnist.train.images.shape\n",
    "print \"Training labels size :\",mnist.train.labels.shape\n",
    "print \"Testing images size :\",mnist.test.images.shape\n",
    "print \"Testing labels size :\",mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating name scope in the graph for the input placeholders\n",
    "\n",
    "Placeholders are later used to process the data in batches of required size. It is a <b>Tensor</b> that may be used as a handle for feeding a value, but not evaluated directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Input_Data\") as scope:\n",
    "  x = tf.placeholder(tf.float32, [None,784], name=\"x\")\n",
    "  y_ = tf.placeholder(tf.float32, [None,10], name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating variables for storing weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784,10]), name=\"weights\")\n",
    "b = tf.Variable(tf.zeros([10]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating name scope in the graph for the applying softmax regression\n",
    "\n",
    "<b>TensorFlow</b> provides direct implementation of the softmax function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Wx_b\") as scope:\n",
    "  y = tf.nn.softmax(tf.matmul(x,W)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating histogram summaries for weights, biases and output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_hist = tf.histogram_summary(\"weights\", W)\n",
    "b_hist = tf.histogram_summary(\"biases\", b)\n",
    "y_hist = tf.histogram_summary(\"y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating name scope in the graph for cross entropy ,i.e, performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Xentropy\") as scope:\n",
    "  cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "  ce_summ = tf.scalar_summary(\"cross entropy\", cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating name scope in the graph for training step \n",
    "\n",
    "The train step operation is added using standard gradient descent optimizer minimizing the cross entropy defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Train\") as scope:\n",
    "  train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating name scope in the graph for testing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Test\") as scope:\n",
    "  correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "  accuracy_summary = tf.scalar_summary(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary steps\n",
    "\n",
    "In the following segment we merge all the summariy operations created above to ease the append of the events to log. We initialize the variables. Then we create a <b>Session</b> object which encapsulates the environment for executing the <b>Operation</b> objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging all the summaries created above\n",
    "merged = tf.merge_all_summaries()\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Creating the session for the graph\n",
    "sess = tf.Session()\n",
    "\n",
    "# Running the session of the graph for the variable initialization defined above\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Summary Writer\n",
    "\n",
    "Initializing the summary writer for the graph to the directory specified in the input flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = tf.train.SummaryWriter(FLAGS.log_dir, sess.graph_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training iterations\n",
    "\n",
    "Running the training steps and evaluating accuracy after every 100 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training steps with batch size 100\n",
      "Accuracy at step 0: 0.098\n",
      "Accuracy at step 100: 0.8864\n",
      "Accuracy at step 200: 0.8846\n",
      "Accuracy at step 300: 0.8248\n",
      "Accuracy at step 400: 0.9057\n",
      "Accuracy at step 500: 0.8733\n",
      "Accuracy at step 600: 0.8846\n",
      "Accuracy at step 700: 0.9153\n",
      "Accuracy at step 800: 0.9147\n",
      "Accuracy at step 900: 0.9164\n"
     ]
    }
   ],
   "source": [
    "print \"Running training steps with batch size\",FLAGS.batch\n",
    "\n",
    "for i in range(FLAGS.max_it):\n",
    "  if i % 100 == 0:  # Record summary data, and the accuracy\n",
    "\n",
    "    # Getting values for the placeholders\n",
    "    feed = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "\n",
    "    # Running the session of the graph for calculating the Accuracy and summaries by the feeding the data fetched above\n",
    "    result = sess.run([merged, accuracy], feed_dict=feed)\n",
    "\n",
    "    summary_str = result[0]\n",
    "    acc = result[1]\n",
    "\n",
    "    # Add summary to the summary writer after every 10 steps\n",
    "    writer.add_summary(summary_str, i)\n",
    "\n",
    "    print(\"Accuracy at step %s: %s\" % (i, acc))\n",
    "  else:\n",
    "    # Getting next 10 data points for training\n",
    "      batch_xs, batch_ys = mnist.train.next_batch(FLAGS.batch)\n",
    "      feed = {x: batch_xs, y_: batch_ys}\n",
    "\n",
    "    # Running the session of the graph for Gradient Descent Optimization with data points fetched above\n",
    "      sess.run(train_step, feed_dict=feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating weights visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = tf.unpack(tf.transpose(W))\n",
    "for i in range(0,10):\n",
    "  w = tf.reshape(weights[i],(-1,28,28,1))\n",
    "  writer.add_summary(sess.run(tf.image_summary(\"weight_\"+str(i),w,max_images=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the accuracy on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation\n",
      "0.9082\n"
     ]
    }
   ],
   "source": [
    "print \"Final Evaluation\"\n",
    "print sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Flow Graphs\n",
    "\n",
    "### Basic Softmax Implementation\n",
    "\n",
    "#### Overview Graph\n",
    "\n",
    "![Overview Graph](./images/overview_graph.png)\n",
    "\n",
    "#### Expanded Graph\n",
    "\n",
    "![Expanded Graph](./images/expanded_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Basic Softmax Implementation\n",
    "\n",
    "Following results were obtained with batch size = 100 and number of iterations = 1000\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "![Expanded Graph](./images/accuracy_basic.png)\n",
    "\n",
    "#### Cross Entropy\n",
    "\n",
    "![Expanded Graph](./images/xentropy_basic.png)\n",
    "\n",
    "#### Weights Visualization\n",
    "\n",
    "##### 0:\n",
    "\n",
    "<img src=\"./images/weight_0.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "\n",
    "##### 1:\n",
    "\n",
    "<img src=\"./images/weight_1.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "\n",
    "##### 2:\n",
    "\n",
    "<img src=\"./images/weight_2.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "\n",
    "##### 3:\n",
    "\n",
    "<img src=\"./images/weight_3.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "\n",
    "##### 4:\n",
    "\n",
    "<img src=\"./images/weight_4.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "\n",
    "##### 5:\n",
    "\n",
    "<img src=\"./images/weight_5.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "\n",
    "##### 6:\n",
    "\n",
    "<img src=\"./images/weight_6.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "\n",
    "##### 7:\n",
    "\n",
    "<img src=\"./images/weight_7.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "\n",
    "##### 8:\n",
    "\n",
    "<img src=\"./images/weight_8.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "\n",
    "##### 9:\n",
    "\n",
    "<img src=\"./images/weight_9.png\" width=\"200\" height=\"200\" />\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
